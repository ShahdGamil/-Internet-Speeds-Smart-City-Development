{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing download speeds in Kentucky counties using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial I will talk about how to:\n",
    "\n",
    "    * Download the Ookla open dataset\n",
    "    * Geocode the tiles to Kentucky counties\n",
    "    * Make a table of the top and bottom 20 counties by download speed\n",
    "    * Map the counties\n",
    "\n",
    "There are two main ways to join these tiles to another geographic dataset: quadkeys and spatial joins. This tutorial will use the spatial join approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download data\n",
    "\n",
    "First, download the data using the link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster Bounds: BoundingBox(left=-180.00208333335, bottom=-65.00208445335001, right=180.00208621335, top=75.00208333335)\n",
      "Indonesia Bounds: [-179.14735527  -14.55254202  179.77845474   71.3525607 ]\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Filepaths\n",
    "raster_file = r\"C:\\Users\\shaho\\Desktop\\VNL_v2_npp_2021_global_vcmslcfg_c202203152300.cf_cvg.tif\"\n",
    "boundary_file = r\"C:\\Users\\shaho\\Downloads\\geoBoundaries-ARE-ADM1-all\\geoBoundaries-ARE-ADM1_simplified.geojson\"\n",
    "output_usa_csv = r\"C:\\Users\\shaho\\Documents\\output.csv\"\n",
    "\n",
    "# Load united emerites's Boundary\n",
    "united emerites = gpd.read_file(boundary_file)\n",
    "united emerites = united emerites.to_crs(epsg=4326)\n",
    "\n",
    "# Open the Raster and Check Overlap\n",
    "with rasterio.open(raster_file) as src:\n",
    "    raster_bounds = box(*src.bounds)\n",
    "    print(\"Raster Bounds:\", src.bounds)\n",
    "    print(\"Indonesia Bounds:\", united emerites.total_bounds)\n",
    "\n",
    "    if not raster_bounds.intersects(united emerites.union_all()):\n",
    "        raise ValueError(\"united emerites's boundary does not overlap with the raster extent.\")\n",
    "\n",
    "    # Clip the raster\n",
    "    Indonesia_geom_list = [feature[\"geometry\"] for feature in Indonesia.__geo_interface__[\"features\"]]\n",
    "    clipped_raster, clipped_transform = mask(src, Indonesia_geom_list, crop=True)\n",
    "\n",
    "# Extract Raster Values\n",
    "light_intensity = clipped_raster[0]\n",
    "rows, cols = np.where(~np.isnan(light_intensity))\n",
    "values = light_intensity[rows, cols]\n",
    "x_coords, y_coords = rasterio.transform.xy(clipped_transform, rows, cols)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'longitude': x_coords,\n",
    "    'latitude': y_coords,\n",
    "    'light_intensity': values\n",
    "})\n",
    "data.to_csv(output_csv, index=False, mode='w')\n",
    "\n",
    "print(f\"Extracted data saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster Metadata: {'driver': 'GTiff', 'dtype': 'uint16', 'nodata': None, 'width': 86401, 'height': 33601, 'count': 1, 'crs': CRS.from_wkt('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]'), 'transform': Affine(0.0041666667, 0.0, -180.00208333335,\n",
      "       0.0, -0.0041666667, 75.00208333335)}\n",
      "Raster Bounds: (-180.00208333335, -65.00208445335001, 180.00208621335, 75.00208333335)\n",
      "CSV file saved: C:\\Users\\pepob\\Desktop\\Data Analysis\\USA_2021_detailed.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter_start(year: int, q: int) -> datetime:\n",
    "    if not 1 <= q <= 4:\n",
    "        raise ValueError(\"Quarter must be within [1, 2, 3, 4]\")\n",
    "\n",
    "    month = [1, 4, 7, 10]\n",
    "    return datetime(year, month[q - 1], 1)\n",
    "\n",
    "\n",
    "def get_tile_url(service_type: str, year: int, q: int) -> str:\n",
    "    dt = quarter_start(year, q)\n",
    "\n",
    "    base_url = \"https://ookla-open-data.s3-us-west-2.amazonaws.com/shapefiles/performance\"\n",
    "    url = f\"{base_url}/type%3D{service_type}/year%3D{dt:%Y}/quarter%3D{q}/{dt:%Y-%m-%d}_performance_{service_type}_tiles.zip\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ookla-open-data.s3-us-west-2.amazonaws.com/shapefiles/performance/type%3Dfixed/year%3D2021/quarter%3D4/2021-10-01_performance_fixed_tiles.zip'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_url = get_tile_url(\"fixed\", 2021, 4) \n",
    "# 4 --> mn 9:12\n",
    "tile_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = gp.read_file(tile_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quadkey</th>\n",
       "      <th>avg_d_kbps</th>\n",
       "      <th>avg_u_kbps</th>\n",
       "      <th>avg_lat_ms</th>\n",
       "      <th>tests</th>\n",
       "      <th>devices</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0022133222330032</td>\n",
       "      <td>26210</td>\n",
       "      <td>32253</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-160.03784 70.63631, -160.03235 70.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022332203013331</td>\n",
       "      <td>8077</td>\n",
       "      <td>2766</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-162.60315 66.89991, -162.59766 66.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0022332203013333</td>\n",
       "      <td>547932</td>\n",
       "      <td>60364</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-162.60315 66.89775, -162.59766 66.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0022332203031111</td>\n",
       "      <td>236319</td>\n",
       "      <td>39674</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-162.60315 66.8956, -162.59766 66.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0022332203031112</td>\n",
       "      <td>268726</td>\n",
       "      <td>47344</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-162.60864 66.89344, -162.60315 66.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354753</th>\n",
       "      <td>3131120230000011</td>\n",
       "      <td>21687</td>\n",
       "      <td>15309</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((169.4696 -46.55886, 169.4751 -46.558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354754</th>\n",
       "      <td>3131120300000300</td>\n",
       "      <td>49173</td>\n",
       "      <td>23851</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((170.17822 -46.08847, 170.18372 -46.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354755</th>\n",
       "      <td>3211031203221110</td>\n",
       "      <td>1047</td>\n",
       "      <td>1136</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((76.36597 -69.38031, 76.37146 -69.380...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354756</th>\n",
       "      <td>3313010232110233</td>\n",
       "      <td>269</td>\n",
       "      <td>974</td>\n",
       "      <td>1206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((164.10828 -74.6934, 164.11377 -74.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354757</th>\n",
       "      <td>3313010232110322</td>\n",
       "      <td>1512</td>\n",
       "      <td>1510</td>\n",
       "      <td>1201</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((164.11377 -74.6934, 164.11926 -74.69...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4354758 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quadkey  avg_d_kbps  avg_u_kbps  avg_lat_ms  tests  devices  \\\n",
       "0        0022133222330032       26210       32253          28      1        1   \n",
       "1        0022332203013331        8077        2766          27     13        3   \n",
       "2        0022332203013333      547932       60364          28      4        2   \n",
       "3        0022332203031111      236319       39674          30     13        5   \n",
       "4        0022332203031112      268726       47344          44     13        2   \n",
       "...                   ...         ...         ...         ...    ...      ...   \n",
       "4354753  3131120230000011       21687       15309          20      4        1   \n",
       "4354754  3131120300000300       49173       23851          13      3        1   \n",
       "4354755  3211031203221110        1047        1136         609      2        1   \n",
       "4354756  3313010232110233         269         974        1206      1        1   \n",
       "4354757  3313010232110322        1512        1510        1201      2        1   \n",
       "\n",
       "                                                  geometry  \n",
       "0        POLYGON ((-160.03784 70.63631, -160.03235 70.6...  \n",
       "1        POLYGON ((-162.60315 66.89991, -162.59766 66.8...  \n",
       "2        POLYGON ((-162.60315 66.89775, -162.59766 66.8...  \n",
       "3        POLYGON ((-162.60315 66.8956, -162.59766 66.89...  \n",
       "4        POLYGON ((-162.60864 66.89344, -162.60315 66.8...  \n",
       "...                                                    ...  \n",
       "4354753  POLYGON ((169.4696 -46.55886, 169.4751 -46.558...  \n",
       "4354754  POLYGON ((170.17822 -46.08847, 170.18372 -46.0...  \n",
       "4354755  POLYGON ((76.36597 -69.38031, 76.37146 -69.380...  \n",
       "4354756  POLYGON ((164.10828 -74.6934, 164.11377 -74.69...  \n",
       "4354757  POLYGON ((164.11377 -74.6934, 164.11926 -74.69...  \n",
       "\n",
       "[4354758 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(tiles)\n",
    "df.to_csv('Ookla.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading polygons...\n",
      "Loading points...\n",
      "Ensuring CRS is consistent...\n",
      "Performing spatial join in chunks...\n",
      "Saving results to 'joined_data.csv'...\n",
      "Spatial join completed successfully. Output file: 'joined_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads\n",
    "\n",
    "# File paths\n",
    "polygons_csv_path = r\"C:\\Users\\shaho\\Ookla.csv\"\n",
    "points_csv_path = r\"C:\\Users\\shaho\\Documents\\output.csv\"\n",
    "output_csv_path = \"joined_data.csv\"\n",
    "\n",
    "# Step 1: Load Polygons CSV\n",
    "print(\"Loading polygons...\")\n",
    "polygons = pd.read_csv(polygons_csv_path)\n",
    "polygons['geometry'] = polygons['geometry'].apply(loads)\n",
    "polygons_gdf = gpd.GeoDataFrame(polygons, geometry='geometry').dropna(subset=['geometry'])\n",
    "\n",
    "# Step 2: Load Points CSV\n",
    "print(\"Loading points...\")\n",
    "points = pd.read_csv(points_csv_path)\n",
    "geometry = [Point(xy) for xy in zip(points['longitude'], points['latitude'])]\n",
    "points_gdf = gpd.GeoDataFrame(points, geometry=geometry).dropna(subset=['geometry'])\n",
    "\n",
    "# Step 3: Ensure CRS is Consistent\n",
    "target_crs = \"EPSG:4326\"\n",
    "print(\"Ensuring CRS is consistent...\")\n",
    "if polygons_gdf.crs != target_crs:\n",
    "    polygons_gdf = polygons_gdf.set_crs(target_crs, allow_override=True)\n",
    "if points_gdf.crs != target_crs:\n",
    "    points_gdf = points_gdf.set_crs(target_crs, allow_override=True)\n",
    "\n",
    "# Step 4: Perform Spatial Join\n",
    "print(\"Performing spatial join in chunks...\")\n",
    "chunk_size = 100000\n",
    "results = []\n",
    "\n",
    "for i in range(0, len(points_gdf), chunk_size):\n",
    "    chunk = points_gdf.iloc[i:i + chunk_size]\n",
    "    try:\n",
    "        result = gpd.sjoin(chunk, polygons_gdf, how=\"left\", predicate=\"within\")\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {i}-{i+chunk_size}: {e}\")\n",
    "\n",
    "# Step 5: Save the Result\n",
    "joined_gdf = pd.concat(results, ignore_index=True)\n",
    "print(f\"Saving results to '{output_csv_path}'...\")\n",
    "joined_gdf.to_csv(output_csv_path, index=False)\n",
    "print(f\"Spatial join completed successfully. Output file: '{output_csv_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data in chunks...\n",
      "Rows with null values in the specified columns have been removed.\n",
      "Cleaned data saved to 'cleaned_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file = r\"C:\\Users\\shaho\\joined_data.csv\" # Replace with your input file path\n",
    "output_file = 'cleaned_data.csv'  # Output file for cleaned data\n",
    "\n",
    "# List of columns to check for null values\n",
    "columns_to_check = ['index_right', 'quadkey', 'avg_d_kbps', 'avg_u_kbps', 'avg_lat_ms', 'tests', 'devices']\n",
    "\n",
    "# Define chunk size for processing\n",
    "chunk_size = 100000  # Adjust based on your system's memory\n",
    "\n",
    "# Initialize an empty list to hold chunks of cleaned data\n",
    "cleaned_chunks = []\n",
    "\n",
    "# Read the file in chunks\n",
    "print(\"Processing data in chunks...\")\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunk_size):\n",
    "    # Remove rows with null values in the specified columns\n",
    "    cleaned_chunk = chunk.dropna(subset=columns_to_check)\n",
    "    # Append the cleaned chunk to the list\n",
    "    cleaned_chunks.append(cleaned_chunk)\n",
    "\n",
    "# Concatenate all cleaned chunks into a single DataFrame\n",
    "data_cleaned = pd.concat(cleaned_chunks, ignore_index=True)\n",
    "\n",
    "# Save the cleaned DataFrame to a new file\n",
    "data_cleaned.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Rows with null values in the specified columns have been removed.\")\n",
    "print(f\"Cleaned data saved to '{output_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
